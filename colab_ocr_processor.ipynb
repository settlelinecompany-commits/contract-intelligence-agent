{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🚀 Fast OCR Processor with GPU Acceleration\n",
        "\n",
        "**Upload your PDF and get OCR results in ~30 seconds!**\n",
        "\n",
        "This notebook uses Surya OCR with GPU acceleration for lightning-fast processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install surya-ocr fastapi uvicorn python-multipart -q\n",
        "\n",
        "print(\"✅ Packages installed successfully!\")\n",
        "print(\"🔧 GPU available:\", torch.cuda.is_available() if 'torch' in globals() else 'Checking...')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any\n",
        "\n",
        "# Import Surya OCR\n",
        "from surya.ocr import run_ocr\n",
        "from surya.model.detection import load_model as load_det_model, load_processor as load_det_processor\n",
        "from surya.model.recognition import load_model as load_rec_model, load_processor as load_rec_processor\n",
        "from PIL import Image\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "print(\"✅ Imports successful!\")\n",
        "print(\"🚀 Ready for fast OCR processing!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Surya models (this will download models on first run)\n",
        "print(\"🔄 Loading Surya OCR models...\")\n",
        "print(\"⏱️ This may take 1-2 minutes on first run...\")\n",
        "\n",
        "det_processor, det_model = load_det_processor(), load_det_model()\n",
        "rec_model, rec_processor = load_rec_model(), load_rec_processor()\n",
        "\n",
        "print(\"✅ Models loaded successfully!\")\n",
        "print(\"🎯 Ready for GPU-accelerated OCR!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "print(\"📄 Upload your PDF file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    pdf_filename = list(uploaded.keys())[0]\n",
        "    print(f\"✅ Uploaded: {pdf_filename}\")\n",
        "    print(f\"📊 File size: {len(uploaded[pdf_filename])} bytes\")\n",
        "else:\n",
        "    print(\"❌ No file uploaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pdf_to_images(pdf_path):\n",
        "    \"\"\"Convert PDF to images\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    images = []\n",
        "    \n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        # Render at 2x scale for better OCR quality\n",
        "        mat = fitz.Matrix(2.0, 2.0)\n",
        "        pix = page.get_pixmap(matrix=mat)\n",
        "        img_data = pix.tobytes(\"png\")\n",
        "        img = Image.open(io.BytesIO(img_data))\n",
        "        images.append(img)\n",
        "    \n",
        "    doc.close()\n",
        "    return images\n",
        "\n",
        "def process_ocr_fast(images, languages=[\"en\", \"ar\"]):\n",
        "    \"\"\"Process images with Surya OCR using GPU acceleration\"\"\"\n",
        "    print(f\"🚀 Processing {len(images)} pages with GPU acceleration...\")\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    # Run OCR with GPU acceleration\n",
        "    predictions = run_ocr(\n",
        "        images, \n",
        "        [languages] * len(images),\n",
        "        det_model, \n",
        "        det_processor,\n",
        "        rec_model, \n",
        "        rec_processor\n",
        "    )\n",
        "    \n",
        "    end_time = datetime.now()\n",
        "    processing_time = end_time - start_time\n",
        "    \n",
        "    # Extract text from predictions\n",
        "    full_text = \"\"\n",
        "    total_confidence = 0\n",
        "    total_lines = 0\n",
        "    \n",
        "    for i, prediction in enumerate(predictions):\n",
        "        page_text = \"\"\n",
        "        page_confidence = 0\n",
        "        page_lines = 0\n",
        "        \n",
        "        for line in prediction.text_lines:\n",
        "            if line.text.strip():\n",
        "                page_text += line.text + \"\\n\"\n",
        "                page_confidence += line.confidence\n",
        "                page_lines += 1\n",
        "        \n",
        "        if page_text.strip():\n",
        "            full_text += f\"\\n--- Page {i+1} ---\\n{page_text}\\n\"\n",
        "            total_confidence += page_confidence\n",
        "            total_lines += page_lines\n",
        "    \n",
        "    avg_confidence = (total_confidence / total_lines) * 100 if total_lines > 0 else 0\n",
        "    \n",
        "    return {\n",
        "        \"extraction_status\": \"success\",\n",
        "        \"extraction_method\": \"Surya OCR (GPU Accelerated)\",\n",
        "        \"raw_text\": full_text.strip(),\n",
        "        \"text_length\": len(full_text.strip()),\n",
        "        \"confidence\": round(avg_confidence, 1),\n",
        "        \"processing_time\": str(processing_time),\n",
        "        \"pages_processed\": len(images),\n",
        "        \"lines_extracted\": total_lines\n",
        "    }\n",
        "\n",
        "print(\"✅ OCR processing functions ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process the uploaded PDF\n",
        "if 'pdf_filename' in locals():\n",
        "    print(f\"🔄 Converting PDF to images...\")\n",
        "    images = pdf_to_images(pdf_filename)\n",
        "    print(f\"📷 Converted to {len(images)} images\")\n",
        "    \n",
        "    print(f\"\\n🚀 Starting GPU-accelerated OCR...\")\n",
        "    result = process_ocr_fast(images)\n",
        "    \n",
        "    print(f\"\\n✅ OCR COMPLETE!\")\n",
        "    print(f\"📊 Results:\")\n",
        "    print(f\"   • Status: {result['extraction_status']}\")\n",
        "    print(f\"   • Method: {result['extraction_method']}\")\n",
        "    print(f\"   • Text Length: {result['text_length']} characters\")\n",
        "    print(f\"   • Confidence: {result['confidence']}%\")\n",
        "    print(f\"   • Processing Time: {result['processing_time']}\")\n",
        "    print(f\"   • Pages: {result['pages_processed']}\")\n",
        "    print(f\"   • Lines: {result['lines_extracted']}\")\n",
        "    \n",
        "    # Store result for download\n",
        "    ocr_result = result\n",
        "else:\n",
        "    print(\"❌ Please upload a PDF file first\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📖 View Extracted Text Results\n",
        "if 'ocr_result' in locals():\n",
        "    print(\"🔍 EXTRACTED TEXT PREVIEW:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Show first 1000 characters\n",
        "    text_preview = ocr_result['raw_text'][:1000]\n",
        "    print(text_preview)\n",
        "    \n",
        "    if len(ocr_result['raw_text']) > 1000:\n",
        "        print(f\"\\n... (showing first 1000 of {len(ocr_result['raw_text'])} characters)\")\n",
        "        print(\"\\n💡 To see full text, run the cell below\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(f\"📊 Summary: {ocr_result['text_length']} characters, {ocr_result['confidence']}% confidence\")\n",
        "else:\n",
        "    print(\"❌ No OCR results found. Please run the OCR processing first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📄 View Full Extracted Text\n",
        "if 'ocr_result' in locals():\n",
        "    print(\"📄 FULL EXTRACTED TEXT:\")\n",
        "    print(\"=\" * 80)\n",
        "    print(ocr_result['raw_text'])\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"✅ Total: {ocr_result['text_length']} characters extracted\")\n",
        "else:\n",
        "    print(\"❌ No OCR results found. Please run the OCR processing first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 💾 Download Results as JSON\n",
        "if 'ocr_result' in locals():\n",
        "    import json\n",
        "    from datetime import datetime\n",
        "    \n",
        "    # Create filename with timestamp\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    filename = f\"tenancy_contract_ocr_{timestamp}.json\"\n",
        "    \n",
        "    # Save to file\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(ocr_result, f, indent=2, ensure_ascii=False)\n",
        "    \n",
        "    print(f\"💾 Results saved to: {filename}\")\n",
        "    \n",
        "    # Download the file\n",
        "    from google.colab import files\n",
        "    files.download(filename)\n",
        "    \n",
        "    print(\"✅ File downloaded to your computer!\")\n",
        "    print(\"🔄 You can now use this data in your Cursor project!\")\n",
        "else:\n",
        "    print(\"❌ No OCR results found. Please run the OCR processing first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download results as JSON\n",
        "if 'ocr_result' in locals():\n",
        "    # Save results to file\n",
        "    result_filename = f\"ocr_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    \n",
        "    with open(result_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(ocr_result, f, indent=2, ensure_ascii=False)\n",
        "    \n",
        "    print(f\"💾 Results saved to: {result_filename}\")\n",
        "    \n",
        "    # Download the file\n",
        "    from google.colab import files\n",
        "    files.download(result_filename)\n",
        "    \n",
        "    print(\"✅ Results downloaded to your computer!\")\n",
        "    print(\"\\n🔄 You can now use this data in your Cursor project!\")\n",
        "else:\n",
        "    print(\"❌ No results to download\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
